{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKBM9jO5emtp"
   },
   "source": [
    "## Set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MnnIzNDiO1MH"
   },
   "outputs": [],
   "source": [
    "from models.models import (\n",
    "    SynthesizerTrn,\n",
    ")\n",
    "\n",
    "from text.symbols import symbols\n",
    "\n",
    "from utils import utils\n",
    "from text import text_to_sequence, cleaned_text_to_sequence\n",
    "\n",
    "from utils import commons\n",
    "import torch\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWKnNm3xjf7g"
   },
   "source": [
    "## Auxilliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oXDKCx1FPnzI"
   },
   "outputs": [],
   "source": [
    "def get_text(text, hps):\n",
    "    # text_norm = text_to_sequence(text, hps.data.text_cleaners)\n",
    "    text_norm = text_to_sequence(text, [\"no_cleaners\"])\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phn_text(phn, hps):\n",
    "    if hps.data.add_blank:\n",
    "        phn = commons.intersperse(phn, 0)\n",
    "    phn = torch.LongTensor(phn)\n",
    "    return phn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf63QzpajptC"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input seetings\n",
    "CONFIG = 'configs/ljs_reproduce.json'\n",
    "MODEL = './logs/exp3/G_420.pth'\n",
    "TEXT = 'mˈoːɹ sˈiəɹɪəsli, ðə fˈækts ʌv hɪz dɪfˈɛkʃən hɐd bɪkˌʌm nˈoʊn, lˈiːvɪŋ hˌɪm ˈoʊpən tʊ ˈɔːlmoʊst ʌnˈænsɚɹəbəl ɐtˈæk baɪ ðoʊz hˌuː əpˈoʊzd hɪz vjˈuːz.'\n",
    "# Inference settings\n",
    "NOISE_SCALE = 0.667\n",
    "LENGTH_SCALE = 1.0\n",
    "MAX_LEN = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jt1t3bhObSji"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded checkpoint './logs/exp3/G_420.pth' (iteration 420)\n"
     ]
    }
   ],
   "source": [
    "hps = utils.get_hparams_from_file(CONFIG)\n",
    "model_path = MODEL\n",
    "text = TEXT\n",
    "\n",
    "net_g = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    hps.models,\n",
    ").cuda(0)\n",
    "\n",
    "net_g.attach_memory_bank(hps.models)\n",
    "\n",
    "_, _, _, epoch_str = utils.load_checkpoint(\n",
    "    model_path, net_g, None\n",
    ")\n",
    "\n",
    "net_g.eval()\n",
    "\n",
    "x = get_text(text, hps).cuda().unsqueeze(0)\n",
    "x_lengths = torch.LongTensor([x.size(1)]).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_hat, mask, *_ = net_g.infer(x, x_lengths, noise_scale=NOISE_SCALE, length_scale=LENGTH_SCALE, max_len=MAX_LEN)\n",
    "    audio = y_hat[0, 0, :].cpu().numpy()\n",
    "\n",
    "scipy.io.wavfile.write(\n",
    "    filename=\"result.wav\",\n",
    "    rate=hps.data.sampling_rate,\n",
    "    data=audio,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
